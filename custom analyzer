
-----------------------------------------------

tokenize

document --> characterfiler(replace incorrect words)

where r you? --> where are you?
remove html tags 
& --> and .... a lot more

next tokenizer based on choosen tokenizer

next token filter 
ex lowercase token filter NoSql-->nosql

============================================

standard analyzer it contains
tokenizer+lowecase token filer+stop token filter

DELETE /blogposts


PUT /blogposts
{
  "settings": {
    "analysis": {
      
      "analyzer": {
        "my_custom_analyzer":
        {
          "type":"custom",
          "char_filter":["html_strip"],
          "tokenizer":"standard",
          "fliter":["lowercase"]
        }
        
      }
    }
  }
  
  , "mappings": {
    "properties":
    {
      "title":{"type":"text"},
      "content":{"type":"text","analyzer":"my_custom_analyzer"},
      "published_data":{"type":"date"}
    }
  }
  
}

GET /blogposts

# to check how inverted indexs
POST /blogposts/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text":"this is html <p> word "
}





PUT /blogposts
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer":{
          "type":"custom",
          "tokenizer":"punctuation",
          "char_filter":["symbol"],
          "filter":["my_stop","lowercase"]
          
        }
      },
      "tokenizer": {
        "punctuation":{
          "type":"pattern",
          "pattern":"[ .!,?]"
        }
      },
      "char_filter": {
        "symbol":
        {
          "type":"mapping",
          "mappings":["& => and",":) => happy",":( => sad "]
        }
      }
      , "filter": {
        "my_stop":{
          "type":"stop",
          "stopwords":"_english_"
        }
      }
    }
  }
}

# and is removed

# to check how inverted indexs
POST /blogposts/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text":"Big Data processing using spark & scala :)"
}

